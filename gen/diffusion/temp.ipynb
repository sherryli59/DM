{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def f(x):\n",
    "    return x**2+2*x+torch.exp(x)+torch.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hutch_trace(f,x,m=100):\n",
    "    repeat_shape = [m]+[1]*(len(x.shape)-1)\n",
    "    x_mult = x.repeat(repeat_shape).detach()\n",
    "    x_mult.requires_grad_(True)\n",
    "    eps = torch.randint(0,2,[m*x.shape[0]]+list(x.shape)[1:]).float()*2-1\n",
    "    eps = eps.to(x.device)\n",
    "    #eps = torch.randn([m*x.shape[0]]+list(x.shape)[1:])\n",
    "    f_e = torch.sum(f(x_mult) * eps)\n",
    "    grad_f_e = torch.autograd.grad(f_e, x_mult)[0]*eps\n",
    "    grad_f_e = grad_f_e.reshape(m,x.shape[0],-1)\n",
    "    return torch.mean(torch.sum(grad_f_e, dim=-1),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hutchpp(f, x, m):\n",
    "    \"\"\"https://arxiv.org/abs/2010.09649\n",
    "    \"\"\"\n",
    "    def grad_eps(eps):\n",
    "        #assume eps has shape (x.shape,m),\n",
    "        #the first dimension is the batch dimension\n",
    "        #return shape (x.shape,m)\n",
    "\n",
    "        m = eps.shape[-1]\n",
    "        # move the last dimension to the front\n",
    "        eps = eps.permute(-1,0,*range(1,len(eps.shape)-1))\n",
    "        eps = eps.reshape(m*x.shape[0],*x.shape[1:])\n",
    "        repeat_shape = [m]+[1]*(len(x.shape)-1)\n",
    "        x_mult = x.repeat(repeat_shape).detach()\n",
    "        x_mult.requires_grad_(True)\n",
    "        f_e = torch.sum(f(x_mult) * eps)\n",
    "        grad_f_e = torch.autograd.grad(f_e, x_mult)[0]*eps\n",
    "        grad_f_e = grad_f_e.reshape(m,x.shape[0],-1).permute(1,2,0)\n",
    "        return grad_f_e\n",
    "\n",
    "    def batch_trace(A):\n",
    "        return torch.mean(torch.diagonal(A,dim1=-2,dim2=-1),dim=-1)\n",
    "\n",
    "    d = torch.prod(torch.tensor(x.shape[1:]))\n",
    "    S = torch.randn(d, m // 3)\n",
    "    G = torch.randn(d, m // 3)\n",
    "    f_e = f(x)\n",
    "    eps = torch.randn(list(x.shape)+[m//3])\n",
    "    grad_f_e = grad_eps(eps)\n",
    "    \n",
    "    Q, _ = torch.qr(grad_f_e)\n",
    "    Q_T = Q.permute(0,2,1)\n",
    "    proj = G - Q @ (Q_T @ G)\n",
    "    proj_T = proj.permute(0,2,1)\n",
    "    print((Q_T @ grad_eps(Q)).shape)\n",
    "    return batch_trace(Q_T @ grad_eps(Q)) + (3./m)*batch_trace(proj_T @ grad_eps(proj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def exact_trace(f,x):\n",
    "      alphabet = string.ascii_lowercase\n",
    "      dydx = torch.vmap(torch.func.jacrev(f))(x)\n",
    "      num_dims = len(x.shape)-1\n",
    "      # Check if the number of dimensions is within the allowed range for einsum\n",
    "      if num_dims > len(alphabet):\n",
    "            raise ValueError(\"Number of dimensions exceeds einsum's capability\")\n",
    "      # Construct the einsum string for the given number of dimensions\n",
    "      # The last two dimensions are supposed to be equal and summed over\n",
    "      einsum_str = alphabet[num_dims] + alphabet[:num_dims] + alphabet[:num_dims] + '->' + alphabet[num_dims]\n",
    "      return torch.einsum(einsum_str,dydx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 98.9216,  85.3511, 102.1591, 147.3731, 102.6866])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(5,4,2,3)\n",
    "hutch_trace(f,x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97.2051,  78.1516, 127.0718, 109.3323, 109.8828])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_trace(f,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 24, 24])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0096, -0.1784,  0.8788, -0.4328, -0.3888])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hutchpp(f,x,900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([16.2197, 22.6289, 18.0896, 21.6987,  9.9557])\n"
     ]
    }
   ],
   "source": [
    "print(2*x.sum(dim=(1,2))+12+torch.exp(x).sum(dim=(1,2))+torch.cos(x).sum(dim=(1,2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a50af526a9532007db5bc48ba67de40b786fc3e756cebc3936df93939941046"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
